{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pipeline de Machine Learning pour la pr√©diction et classification des soudures",
   "id": "4a92b5eee72a3fe2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:26.099237Z",
     "start_time": "2025-10-28T14:49:26.091236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"deep\")"
   ],
   "id": "e485091c9106c108",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:27.484663Z",
     "start_time": "2025-10-28T14:49:27.429133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === 1) Chargement du dataset nettoy√©\n",
    "DATA_PATH = Path.cwd().parents[0] / \"cleaning\" / \"outputs\" / \"weld_quality_clean_from_hf.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "df.head()"
   ],
   "id": "d3ac61e02bc5f10f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Shape: (1652, 58)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Carbon concentration / (weight%)  Silicon concentration / (weight%)  \\\n",
       "0                             0.037                               0.30   \n",
       "1                             0.037                               0.30   \n",
       "2                             0.037                               0.30   \n",
       "3                             0.037                               0.31   \n",
       "4                             0.037                               0.31   \n",
       "\n",
       "   Manganese concentration / (weight%)  Sulphur concentration / (weight%)  \\\n",
       "0                                 0.65                              0.008   \n",
       "1                                 0.65                              0.008   \n",
       "2                                 0.65                              0.008   \n",
       "3                                 1.03                              0.007   \n",
       "4                                 1.03                              0.007   \n",
       "\n",
       "   Phosphorus concentration / (weight%)  Nickel concentration / (weight%)  \\\n",
       "0                                 0.012                               0.0   \n",
       "1                                 0.012                               0.0   \n",
       "2                                 0.012                               0.0   \n",
       "3                                 0.014                               0.0   \n",
       "4                                 0.014                               0.0   \n",
       "\n",
       "   Chromium concentration / (weight%)  Molybdenum concentration / (weight%)  \\\n",
       "0                                 0.0                                   0.0   \n",
       "1                                 0.0                                   0.0   \n",
       "2                                 0.0                                   0.0   \n",
       "3                                 0.0                                   0.0   \n",
       "4                                 0.0                                   0.0   \n",
       "\n",
       "   Vanadium concentration / (weight%)  Copper concentration / (weight%)  ...  \\\n",
       "0                                 0.0                               0.0  ...   \n",
       "1                                 0.0                               0.0  ...   \n",
       "2                                 0.0                               0.0  ...   \n",
       "3                                 0.0                               0.0  ...   \n",
       "4                                 0.0                               0.0  ...   \n",
       "\n",
       "   Niobium concentration / (wt%) Tin concentration / (wt%)  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "\n",
       "   Arsenic concentration / (wt%)  Antimony concentration / (wt%)  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             0.0   \n",
       "\n",
       "   Type of weld;_raw  AC or DC_raw  Electrode positive or negative_raw  \\\n",
       "0                MMA            DC                                   +   \n",
       "1                MMA            DC                                   +   \n",
       "2                MMA            DC                                   +   \n",
       "3                MMA            DC                                   +   \n",
       "4                MMA            DC                                   +   \n",
       "\n",
       "   type_weld_enc  acdc_enc  polarity_enc  \n",
       "0              0       1.0             1  \n",
       "1              0       1.0             1  \n",
       "2              0       1.0             1  \n",
       "3              0       1.0             1  \n",
       "4              0       1.0             1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carbon concentration / (weight%)</th>\n",
       "      <th>Silicon concentration / (weight%)</th>\n",
       "      <th>Manganese concentration / (weight%)</th>\n",
       "      <th>Sulphur concentration / (weight%)</th>\n",
       "      <th>Phosphorus concentration / (weight%)</th>\n",
       "      <th>Nickel concentration / (weight%)</th>\n",
       "      <th>Chromium concentration / (weight%)</th>\n",
       "      <th>Molybdenum concentration / (weight%)</th>\n",
       "      <th>Vanadium concentration / (weight%)</th>\n",
       "      <th>Copper concentration / (weight%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Niobium concentration / (wt%)</th>\n",
       "      <th>Tin concentration / (wt%)</th>\n",
       "      <th>Arsenic concentration / (wt%)</th>\n",
       "      <th>Antimony concentration / (wt%)</th>\n",
       "      <th>Type of weld;_raw</th>\n",
       "      <th>AC or DC_raw</th>\n",
       "      <th>Electrode positive or negative_raw</th>\n",
       "      <th>type_weld_enc</th>\n",
       "      <th>acdc_enc</th>\n",
       "      <th>polarity_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMA</td>\n",
       "      <td>DC</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMA</td>\n",
       "      <td>DC</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMA</td>\n",
       "      <td>DC</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMA</td>\n",
       "      <td>DC</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMA</td>\n",
       "      <td>DC</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 58 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:29.414694Z",
     "start_time": "2025-10-28T14:49:29.405708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.isna().sum().sort_values(ascending=False).head(10))"
   ],
   "id": "6a3df3f516fd2dd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1652, 58)\n",
      "Index(['Carbon concentration / (weight%)', 'Silicon concentration / (weight%)',\n",
      "       'Manganese concentration / (weight%)',\n",
      "       'Sulphur concentration / (weight%)',\n",
      "       'Phosphorus concentration / (weight%)',\n",
      "       'Nickel concentration / (weight%)',\n",
      "       'Chromium concentration / (weight%)',\n",
      "       'Molybdenum concentration / (weight%)',\n",
      "       'Vanadium concentration / (weight%)',\n",
      "       'Copper concentration / (weight%)', 'Cobalt concentration / (weight%)',\n",
      "       'Tungsten concentration / (weight%)',\n",
      "       'Oxygen concentration / parts per million by weight',\n",
      "       'Titanium concentration / parts per million by weight',\n",
      "       'Nitrogen concentration / parts per million by weight',\n",
      "       'Aluminium concentration / parts per million by weight',\n",
      "       'Boron concentration / parts per million by weight',\n",
      "       'Niobium concentration / parts per million by weight',\n",
      "       'Tin concentration / parts per million by weight',\n",
      "       'Arsenic concentration / parts per million by weight',\n",
      "       'Antimony concentration / parts per million by weight', 'Current / A',\n",
      "       'Voltage / V', 'AC or DC', 'Electrode positive or negative',\n",
      "       'Heat input / kJmm-1', 'Interpass temperature / ¬∞C', 'Type of weld;',\n",
      "       'Post weld heat treatment temperature / ¬∞C',\n",
      "       'Post weld heat treatment time / hours', 'Yield strength / MPa',\n",
      "       'Ultimate tensile strength / MPa', 'Elongation / %',\n",
      "       'Reduction of Area / %', 'Charpy temperature / ¬∞C',\n",
      "       'Charpy impact toughness / J', 'Hardness / kgmm-2', '50 % FATT',\n",
      "       'Primary ferrite in microstructure / %',\n",
      "       'Ferrite with second phase / %', 'Acicular ferrite / %',\n",
      "       'Martensite / %', 'Ferrite with carbide aggreagate / %', 'Weld ID',\n",
      "       'Titanium concentration / (wt%)', 'Nitrogen concentration / (wt%)',\n",
      "       'Aluminium concentration / (wt%)', 'Boron concentration / (wt%)',\n",
      "       'Niobium concentration / (wt%)', 'Tin concentration / (wt%)',\n",
      "       'Arsenic concentration / (wt%)', 'Antimony concentration / (wt%)',\n",
      "       'Type of weld;_raw', 'AC or DC_raw',\n",
      "       'Electrode positive or negative_raw', 'type_weld_enc', 'acdc_enc',\n",
      "       'polarity_enc'],\n",
      "      dtype='object')\n",
      "Ferrite with carbide aggreagate / %      1563\n",
      "Martensite / %                           1563\n",
      "Acicular ferrite / %                     1562\n",
      "Ferrite with second phase / %            1562\n",
      "Primary ferrite in microstructure / %    1556\n",
      "Elongation / %                            952\n",
      "Reduction of Area / %                     947\n",
      "Ultimate tensile strength / MPa           914\n",
      "Yield strength / MPa                      872\n",
      "Charpy impact toughness / J               773\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:30.821132Z",
     "start_time": "2025-10-28T14:49:30.810129Z"
    }
   },
   "cell_type": "code",
   "source": "df.dtypes.value_counts()",
   "id": "ce105e5c8410939a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    46\n",
       "object     10\n",
       "int64       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:32.671184Z",
     "start_time": "2025-10-28T14:49:32.661146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# üéØ D√©finition des cibles et features\n",
    "target_cols = [\n",
    "    'Yield strength / MPa',\n",
    "    'Ultimate tensile strength / MPa',\n",
    "    'Elongation / %',\n",
    "    'Hardness / kgmm-2'\n",
    "]\n",
    "feature_cols = [c for c in df.columns if c not in target_cols + ['Weld ID']]"
   ],
   "id": "b885a1460c6a56a5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:34.129318Z",
     "start_time": "2025-10-28T14:49:34.106366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# S√©curiser les cibles en num√©rique\n",
    "import numpy as np, pandas as pd\n",
    "for c in target_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "X_all = df[feature_cols].copy()"
   ],
   "id": "d67ed67c91b31ff0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:35.888256Z",
     "start_time": "2025-10-28T14:49:35.875250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lignes labellis√©es (toutes cibles pr√©sentes)\n",
    "label_mask = df[target_cols].notna().all(axis=1)\n",
    "X_labeled  = X_all.loc[label_mask].copy()\n",
    "y_labeled  = df.loc[label_mask, target_cols].copy()\n",
    "X_unlabeled = X_all.loc[~label_mask].copy()\n",
    "\n",
    "print(f\"[INFO] Lignes labellis√©es : {X_labeled.shape[0]} / {df.shape[0]}\")\n",
    "print(f\"[INFO] Lignes non labellis√©es gard√©es pour inference : {X_unlabeled.shape[0]}\")\n",
    "assert np.isfinite(y_labeled.to_numpy()).all(), \"y contient des valeurs non finies.\""
   ],
   "id": "fce0cdb4846f80d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Lignes labellis√©es : 54 / 1652\n",
      "[INFO] Lignes non labellis√©es gard√©es pour inference : 1598\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:37.536061Z",
     "start_time": "2025-10-28T14:49:37.527027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# üî™ Drop des colonnes 100% NaN (sur les labell√©es) ‚Äî version stable\n",
    "# On enl√®ve des features qui sont enti√®rement NaN c√¥t√© labell√©, et on applique le m√™me drop √† l‚Äôunlabeled.\n",
    "all_nan_cols = X_labeled.columns[X_labeled.isna().all(axis=0)]\n",
    "if len(all_nan_cols) > 0:\n",
    "    print(\"[INFO] Colonnes 100% NaN (labell√©) ‚Äî drop:\", list(all_nan_cols))\n",
    "    X_labeled   = X_labeled.drop(columns=all_nan_cols)\n",
    "    X_unlabeled = X_unlabeled.drop(columns=all_nan_cols, errors=\"ignore\")"
   ],
   "id": "c5da985a22eeb11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Colonnes 100% NaN (labell√©) ‚Äî drop: ['Charpy temperature / ¬∞C', 'Charpy impact toughness / J', 'Primary ferrite in microstructure / %', 'Ferrite with second phase / %', 'Acicular ferrite / %', 'Martensite / %', 'Ferrite with carbide aggreagate / %']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:38.705895Z",
     "start_time": "2025-10-28T14:49:38.645385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Helpers + STRATIFIED SPLITS\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 9.1) Fonction de label binaire m√©tier\n",
    "TARGETS = ['Yield strength / MPa','Ultimate tensile strength / MPa','Elongation / %','Hardness / kgmm-2']\n",
    "def make_label(df_targets, thr, need_at_least=3, hard_thr=None):\n",
    "    scores = np.zeros(len(df_targets), dtype=int)\n",
    "    for c in df_targets.columns:\n",
    "        if c == 'Hardness / kgmm-2' and hard_thr is not None:\n",
    "            good = (df_targets[c] <= hard_thr)\n",
    "        else:\n",
    "            good = (df_targets[c] >= thr[c])\n",
    "        scores += good.astype(int)\n",
    "    return (scores >= min(need_at_least, len(df_targets.columns))).astype(int)\n",
    "\n",
    "# --- 9.2) Pour stratifier, on a besoin d'un y_bin provisoire (pas pour entra√Æner !)\n",
    "present_targets_all = [c for c in TARGETS if c in y_labeled.columns]\n",
    "med_all = {c: y_labeled[c].median() for c in present_targets_all}\n",
    "hard90_all = np.quantile(y_labeled['Hardness / kgmm-2'].dropna(), 0.90) if 'Hardness / kgmm-2' in present_targets_all else None\n",
    "y_bin_full = make_label(y_labeled[present_targets_all], med_all, need_at_least=3, hard_thr=hard90_all)\n",
    "\n",
    "# --- 9.3) Split stratifi√© (recommand√©: 60/20/20 sur les 54 labell√©es)\n",
    "X_tr, X_tmp, y_tr, y_tmp, yb_tr, yb_tmp = train_test_split(\n",
    "    X_labeled, y_labeled, y_bin_full, test_size=0.40, stratify=y_bin_full, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test, yb_val, yb_test = train_test_split(\n",
    "    X_tmp, y_tmp, yb_tmp, test_size=0.50, stratify=yb_tmp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT] train={len(X_tr)} | val={len(X_val)} | test={len(X_test)}  (total={len(X_labeled)})\")\n",
    "\n",
    "# --- 9.4) D√©finition des seuils m√©tier FINAUX √† partir de y_tr uniquement\n",
    "present_targets_tr = [c for c in TARGETS if c in y_tr.columns]\n",
    "thr_median_tr = {c: y_tr[c].median() for c in present_targets_tr}\n",
    "hard_thr_tr   = np.quantile(y_tr['Hardness / kgmm-2'].dropna(), 0.90) if 'Hardness / kgmm-2' in present_targets_tr else None\n",
    "\n",
    "y_train_bin = make_label(y_tr[present_targets_tr],  thr_median_tr, need_at_least=3, hard_thr=hard_thr_tr)\n",
    "y_val_bin   = make_label(y_val[present_targets_tr], thr_median_tr, need_at_least=3, hard_thr=hard_thr_tr)\n",
    "y_test_bin  = make_label(y_test[present_targets_tr],thr_median_tr, need_at_least=3, hard_thr=hard_thr_tr)\n",
    "\n",
    "print(\"[LABEL] r√©partition train/val/test :\", np.bincount(y_train_bin), np.bincount(y_val_bin), np.bincount(y_test_bin))"
   ],
   "id": "69626a5f3a7f435e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPLIT] train=32 | val=11 | test=11  (total=54)\n",
      "[LABEL] r√©partition train/val/test : [20 12] [6 5] [8 3]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:41.066613Z",
     "start_time": "2025-10-28T14:49:40.871734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# PREPROCESS (fit sur train + unlabeled uniquement)\n",
    "# =========================\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Colonnes num√©riques conserv√©es\n",
    "num_cols = X_tr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# üîß Aligner X_unlabeled / X_val / X_test sur ces colonnes (ajouter manquantes en NaN)\n",
    "missing_in_unlabeled = [c for c in num_cols if c not in X_unlabeled.columns]\n",
    "if missing_in_unlabeled:\n",
    "    for c in missing_in_unlabeled:\n",
    "        X_unlabeled[c] = np.nan\n",
    "\n",
    "for _df in (X_val, X_test):\n",
    "    miss = [c for c in num_cols if c not in _df.columns]\n",
    "    if miss:\n",
    "        for c in miss:\n",
    "            _df[c] = np.nan\n",
    "\n",
    "# Re-indexage pour garantir m√™me ordre de colonnes\n",
    "X_unlabeled = X_unlabeled.reindex(columns=num_cols)\n",
    "X_val       = X_val.reindex(columns=num_cols)\n",
    "X_test      = X_test.reindex(columns=num_cols)\n",
    "\n",
    "# Vues num√©riques coh√©rentes\n",
    "X_tr_num   = X_tr[num_cols].copy()\n",
    "X_val_num  = X_val[num_cols].copy()\n",
    "X_test_num = X_test[num_cols].copy()\n",
    "X_u_num    = X_unlabeled[num_cols].copy()\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit imputer/scaler sur (train + unlabeled) ‚Äî en DataFrame\n",
    "X_fit = pd.concat([X_tr_num, X_u_num], axis=0)\n",
    "X_fit_imp = pd.DataFrame(imp.fit_transform(X_fit), columns=num_cols, index=X_fit.index)\n",
    "# ‚¨áÔ∏è fit scaler sur un DF (avec noms)\n",
    "scaler.fit(X_fit_imp)\n",
    "\n",
    "# Transformations coh√©rentes (toujours DF -> DF)\n",
    "def pp(df_):\n",
    "    # imputation -> DF avec m√™mes colonnes/index\n",
    "    arr_imp = imp.transform(df_)\n",
    "    df_imp  = pd.DataFrame(arr_imp, columns=num_cols, index=df_.index)\n",
    "    # scaling -> DF avec m√™mes colonnes/index\n",
    "    arr_std = scaler.transform(df_imp)\n",
    "    df_std  = pd.DataFrame(arr_std, columns=num_cols, index=df_.index)\n",
    "    # selon ton pipeline en aval, renvoie .values ou laisse en DF\n",
    "    return df_std.values  # ou return df_std si tu pr√©f√®res rester en DF jusqu‚Äôaux mod√®les\n",
    "\n",
    "# et maintenant :\n",
    "X_tr_pp   = pp(X_tr_num)\n",
    "X_val_pp  = pp(X_val_num)\n",
    "X_test_pp = pp(X_test_num)\n",
    "X_u_pp    = pp(X_u_num)"
   ],
   "id": "c9dacabea1206472",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:44.423389Z",
     "start_time": "2025-10-28T14:49:43.683725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# (Option) LABEL SPREADING ‚Äî robustifi√©\n",
    "# =========================\n",
    "import numpy as np\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "X_ssl_all = np.vstack([X_tr_pp, X_u_pp])\n",
    "y_ssl = np.full(X_ssl_all.shape[0], -1, dtype=int)\n",
    "y_ssl[:len(X_tr_pp)] = y_train_bin\n",
    "\n",
    "def median_gamma(X, max_samples=1000):\n",
    "    # gamma ~ 1 / (median distance)^2\n",
    "    n = X.shape[0]\n",
    "    if n > max_samples:\n",
    "        idx = np.random.RandomState(42).choice(n, size=max_samples, replace=False)\n",
    "        Xs = X[idx]\n",
    "    else:\n",
    "        Xs = X\n",
    "    # pairwise on a subset of rows to estimate median distance\n",
    "    d = pairwise_distances(Xs, Xs, metric=\"euclidean\")\n",
    "    d = d[np.triu_indices_from(d, k=1)]\n",
    "    med = np.median(d[d > 0]) if np.any(d > 0) else 1.0\n",
    "    return 1.0 / (med**2 if med > 0 else 1.0)\n",
    "\n",
    "def safe_auc(y_true, scores):\n",
    "    s = np.nan_to_num(scores, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "    # si toutes les valeurs sont identiques, AUC n‚Äôa pas de sens\n",
    "    if np.unique(s).size < 2:\n",
    "        return float(\"nan\")\n",
    "    try:\n",
    "        return roc_auc_score(y_true, s)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def eval_ls(model, X_val_pp, y_val_bin):\n",
    "    p = model.predict_proba(X_val_pp)[:, 1]\n",
    "    p = np.nan_to_num(p, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "    yhat = (p >= 0.5).astype(int)\n",
    "    f1 = f1_score(y_val_bin, yhat)\n",
    "    auc = safe_auc(y_val_bin, p)\n",
    "    return f1, auc, p\n",
    "\n",
    "# grille robuste : gamma auto + plusieurs k\n",
    "gamma_auto = median_gamma(X_ssl_all, max_samples=1200)\n",
    "cands = [\n",
    "    (\"rbf\", gamma_auto), (\"rbf\", gamma_auto/2), (\"rbf\", gamma_auto*2),\n",
    "    (\"knn\", 10), (\"knn\", 20), (\"knn\", 30), (\"knn\", 50)\n",
    "]\n",
    "\n",
    "best_ls, best = None, (-np.inf,)\n",
    "\n",
    "for kernel, param in cands:\n",
    "    if kernel == \"rbf\":\n",
    "        ls = LabelSpreading(kernel=\"rbf\", gamma=float(param), alpha=0.2, max_iter=30, tol=1e-3)\n",
    "    else:\n",
    "        k = int(param)\n",
    "        # k au moins 2 et pas plus que n-1\n",
    "        k = max(2, min(k, X_ssl_all.shape[0]-1))\n",
    "        ls = LabelSpreading(kernel=\"knn\", n_neighbors=k, alpha=0.2, max_iter=30, tol=1e-3)\n",
    "\n",
    "    ls.fit(X_ssl_all, y_ssl)\n",
    "    f1, auc, p = eval_ls(ls, X_val_pp, y_val_bin)\n",
    "    score = (f1, np.nan_to_num(auc))\n",
    "    if score > best:\n",
    "        best, best_ls = score, ls\n",
    "\n",
    "print(f\"[LS] best on val: F1={best[0]:.3f} | AUC={best[1]:.3f}\")\n",
    "\n",
    "# üîÅ fallback : si l‚ÄôAUC reste NaN/0 avec Spreading, tente LabelPropagation (hard clamping) pour info\n",
    "try:\n",
    "    lp = LabelPropagation(kernel=\"knn\", n_neighbors=20, max_iter=30, tol=1e-3)\n",
    "    lp.fit(X_ssl_all, y_ssl)\n",
    "    f1_lp, auc_lp, _ = eval_ls(lp, X_val_pp, y_val_bin)\n",
    "    print(f\"[LP] (check) F1={f1_lp:.3f} | AUC={auc_lp:.3f}\")\n",
    "except Exception as e:\n",
    "    print(\"[LP] skip:\", e)"
   ],
   "id": "5a9eae60b8c347dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LS] best on val: F1=1.000 | AUC=1.000\n",
      "[LP] (check) F1=0.889 | AUC=1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guillaume PORET\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Guillaume PORET\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Guillaume PORET\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=30 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guillaume PORET\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:48.860571Z",
     "start_time": "2025-10-28T14:49:48.793640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# TEACHER‚ÄìSTUDENT avec quotas\n",
    "# =========================\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "def add_gaussian_noise(X, sigma=0.01, seed=42):\n",
    "    rs = np.random.RandomState(seed)\n",
    "    return X + rs.normal(0.0, sigma, size=X.shape)\n",
    "\n",
    "def class_weight_ratio(y):\n",
    "    pos = np.sum(y==1); neg = np.sum(y==0)\n",
    "    return max(1.0, (neg / max(1, pos)))\n",
    "\n",
    "def make_rf(seed=42):\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=900, max_depth=None, min_samples_leaf=1,\n",
    "        class_weight=\"balanced_subsample\", n_jobs=-1, random_state=seed\n",
    "    )\n",
    "\n",
    "def make_xgb(y_train=None, seed=42):\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "    except Exception as e:\n",
    "        print(f\"[XGB] indisponible: {e}\")\n",
    "        return None\n",
    "    spw = class_weight_ratio(y_train) if y_train is not None else 1.0\n",
    "    return XGBClassifier(\n",
    "        n_estimators=1000, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.85, colsample_bytree=0.85,\n",
    "        reg_lambda=1.0, reg_alpha=0.0,\n",
    "        random_state=seed, n_jobs=-1, tree_method=\"hist\",\n",
    "        eval_metric=\"logloss\", scale_pos_weight=spw\n",
    "    )\n",
    "\n",
    "def teacher_student_quota(model_maker, X_l, y_l, X_u,\n",
    "                          thresholds=(0.99,0.97,0.95,0.93,0.90),\n",
    "                          max_add_frac=0.10,  # 10% du pool par it√©ration\n",
    "                          aug_sigma=0.01, seed=42):\n",
    "    teacher = model_maker(seed=seed)\n",
    "    teacher.fit(X_l, y_l)\n",
    "\n",
    "    added = np.zeros(len(X_u), dtype=bool)\n",
    "    total = 0\n",
    "    for it, thr in enumerate(thresholds, start=1):\n",
    "        pool_idx = np.where(~added)[0]\n",
    "        if pool_idx.size == 0: break\n",
    "\n",
    "        proba = teacher.predict_proba(X_u[pool_idx])[:,1]\n",
    "        conf = np.maximum(proba, 1.0 - proba)\n",
    "        yhat = (proba>=0.5).astype(int)\n",
    "        keep = conf >= thr\n",
    "        if not np.any(keep):\n",
    "            continue\n",
    "        idx_keep = pool_idx[keep]\n",
    "\n",
    "        # quotas par classe\n",
    "        pos_idx = idx_keep[yhat[keep]==1]\n",
    "        neg_idx = idx_keep[yhat[keep]==0]\n",
    "        cap = int(max_add_frac * len(pool_idx))\n",
    "        half = max(1, cap//2)\n",
    "        pos_take = pos_idx[:half]\n",
    "        neg_take = neg_idx[:half]\n",
    "        add_idx = np.concatenate([pos_take, neg_take])\n",
    "        if add_idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        X_pl = X_u[add_idx]\n",
    "        y_pl = teacher.predict(X_pl)  # labels durs pour stabiliser\n",
    "        # Consistency par bruit\n",
    "        X_aug = np.vstack([X_l, add_gaussian_noise(X_l, aug_sigma, seed+it),\n",
    "                           X_pl, add_gaussian_noise(X_pl, aug_sigma, seed+100+it)])\n",
    "        y_aug = np.concatenate([y_l, y_l, y_pl, y_pl])\n",
    "\n",
    "        student = model_maker(seed=seed+it)\n",
    "        student.fit(X_aug, y_aug)\n",
    "        teacher = student\n",
    "        added[add_idx] = True\n",
    "        total += add_idx.size\n",
    "        print(f\"[TS] it{it} thr={thr:.2f} +{add_idx.size} (pos={len(pos_take)} / neg={len(neg_take)}) total={total}\")\n",
    "\n",
    "    return teacher, dict(added=int(total), remain=int((~added).sum()))"
   ],
   "id": "c6795138b1f92d1a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:57.246480Z",
     "start_time": "2025-10-28T14:49:52.146003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Entra√Ænement RF & XGB (Teacher‚ÄìStudent) + ensemble\n",
    "# =========================\n",
    "rf_teacher, rf_stats = teacher_student_quota(make_rf,  X_tr_pp, y_train_bin, X_u_pp,\n",
    "                                             thresholds=(0.99,0.97,0.95,0.93,0.90),\n",
    "                                             max_add_frac=0.10, aug_sigma=0.01, seed=42)\n",
    "print(\"[RF] Stats:\", rf_stats)\n",
    "\n",
    "xgb_teacher, xgb_stats = teacher_student_quota(make_xgb, X_tr_pp, y_train_bin, X_u_pp,\n",
    "                                               thresholds=(0.99,0.97,0.95,0.93,0.90),\n",
    "                                               max_add_frac=0.10, aug_sigma=0.01, seed=777)\n",
    "print(\"[XGB] Stats:\", xgb_stats)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "candidates = {}\n",
    "\n",
    "# RF ‚Üí val\n",
    "if rf_teacher is not None:\n",
    "    pr = rf_teacher.predict_proba(X_val_pp)[:,1]\n",
    "    yr = (pr>=0.5).astype(int)\n",
    "    candidates[\"TS_RF\"] = dict(f1=f1_score(y_val_bin, yr), auc=roc_auc_score(y_val_bin, pr), proba=pr)\n",
    "\n",
    "# XGB ‚Üí val\n",
    "if xgb_teacher is not None:\n",
    "    try:\n",
    "        px = xgb_teacher.predict_proba(X_val_pp)[:,1]\n",
    "        yx = (px>=0.5).astype(int)\n",
    "        candidates[\"TS_XGB\"] = dict(f1=f1_score(y_val_bin, yx), auc=roc_auc_score(y_val_bin, px), proba=px)\n",
    "    except Exception as e:\n",
    "        print(\"[XGB] predict_proba indisponible:\", e)\n",
    "\n",
    "# Ensemble (poids AUC sur val)\n",
    "if (\"TS_RF\" in candidates) and (\"TS_XGB\" in candidates):\n",
    "    auc_rf = candidates[\"TS_RF\"][\"auc\"]\n",
    "    auc_xg = candidates[\"TS_XGB\"][\"auc\"]\n",
    "    s = max(auc_rf+auc_xg, 1e-9)\n",
    "    w_rf, w_xg = auc_rf/s, auc_xg/s\n",
    "    p_ens = w_rf*candidates[\"TS_RF\"][\"proba\"] + w_xg*candidates[\"TS_XGB\"][\"proba\"]\n",
    "    y_ens = (p_ens>=0.5).astype(int)\n",
    "    candidates[\"TS_Ensemble\"] = dict(f1=f1_score(y_val_bin, y_ens), auc=roc_auc_score(y_val_bin, p_ens),\n",
    "                                     proba=p_ens, weights=(w_rf, w_xg))\n",
    "\n",
    "# S√©lection champion sur validation (F1 puis AUC)\n",
    "champ_name, champ_stats = max(candidates.items(), key=lambda kv: (kv[1][\"f1\"], kv[1][\"auc\"]))\n",
    "\n",
    "print(f\"[üèÜ Champion (val)] {champ_name} ‚Äî F1={champ_stats['f1']:.3f} | AUC={champ_stats['auc']:.3f}\")"
   ],
   "id": "d714904792d9b4be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] Stats: {'added': 0, 'remain': 1598}\n",
      "[TS] it1 thr=0.99 +2 (pos=2 / neg=0) total=2\n",
      "[TS] it2 thr=0.97 +111 (pos=79 / neg=32) total=113\n",
      "[TS] it3 thr=0.95 +148 (pos=74 / neg=74) total=261\n",
      "[TS] it4 thr=0.93 +110 (pos=44 / neg=66) total=371\n",
      "[TS] it5 thr=0.90 +67 (pos=6 / neg=61) total=438\n",
      "[XGB] Stats: {'added': 438, 'remain': 1160}\n",
      "[üèÜ Champion (val)] TS_Ensemble ‚Äî F1=0.833 | AUC=0.867\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:49:59.613942Z",
     "start_time": "2025-10-28T14:49:59.566426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def print_clf_report(name, proba, y_true, thr=0.5):\n",
    "    y_pred = (proba >= thr).astype(int)\n",
    "    print(f\"\\n--- {name} (thr={thr:.2f}) ---\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "if \"TS_RF\" in candidates:       print_clf_report(\"TS_RF\", candidates[\"TS_RF\"][\"proba\"], y_val_bin)\n",
    "if \"TS_XGB\" in candidates:      print_clf_report(\"TS_XGB\", candidates[\"TS_XGB\"][\"proba\"], y_val_bin)\n",
    "if \"TS_Ensemble\" in candidates: print_clf_report(\"TS_Ensemble\", candidates[\"TS_Ensemble\"][\"proba\"], y_val_bin)"
   ],
   "id": "9d41ea2ac0a924e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TS_RF (thr=0.50) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.714     0.833     0.769         6\n",
      "           1      0.750     0.600     0.667         5\n",
      "\n",
      "    accuracy                          0.727        11\n",
      "   macro avg      0.732     0.717     0.718        11\n",
      "weighted avg      0.731     0.727     0.723        11\n",
      "\n",
      "\n",
      "--- TS_XGB (thr=0.50) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.500     0.667         6\n",
      "           1      0.625     1.000     0.769         5\n",
      "\n",
      "    accuracy                          0.727        11\n",
      "   macro avg      0.812     0.750     0.718        11\n",
      "weighted avg      0.830     0.727     0.713        11\n",
      "\n",
      "\n",
      "--- TS_Ensemble (thr=0.50) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.667     0.800         6\n",
      "           1      0.714     1.000     0.833         5\n",
      "\n",
      "    accuracy                          0.818        11\n",
      "   macro avg      0.857     0.833     0.817        11\n",
      "weighted avg      0.870     0.818     0.815        11\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:48:28.944729Z",
     "start_time": "2025-10-28T14:48:11.829156Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install statsmodels",
   "id": "9b555f5a5bef0751",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.5-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\guillaume poret\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.5-cp310-cp310-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.1/9.6 MB 23.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.6 MB 23.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.6 MB 23.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.6 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.5/9.6 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.6 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.2 statsmodels-0.14.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:50:09.717881Z",
     "start_time": "2025-10-28T14:50:09.658358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# üîç DIAG ENSEMBLE ‚Äî AVANT CALIBRATION (sur VALIDATION)\n",
    "# ============================================\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Probas brutes sur la validation\n",
    "pr   = candidates[\"TS_RF\"][\"proba\"]\n",
    "px   = candidates[\"TS_XGB\"][\"proba\"]\n",
    "p_ens= candidates[\"TS_Ensemble\"][\"proba\"]\n",
    "\n",
    "# Pr√©dictions binaires (thr=0.5 pour le diag)\n",
    "yr   = (pr>=0.5).astype(int)\n",
    "yx   = (px>=0.5).astype(int)\n",
    "yens = (p_ens>=0.5).astype(int)\n",
    "\n",
    "# 1) Taux de d√©saccord RF vs XGB\n",
    "disagree = float(np.mean(yr != yx))\n",
    "\n",
    "# 2) Corr√©lation des erreurs RF vs XGB\n",
    "err_corr = float(np.corrcoef((yr!=y_val_bin), (yx!=y_val_bin))[0,1])\n",
    "\n",
    "# 3) Gain F1 de l‚Äôensemble vs chaque mod√®le\n",
    "d_rf = f1_score(y_val_bin, yens) - f1_score(y_val_bin, yr)\n",
    "d_xg = f1_score(y_val_bin, yens) - f1_score(y_val_bin, yx)\n",
    "\n",
    "# 4) ŒîAUC de l‚Äôensemble\n",
    "auc_rf  = roc_auc_score(y_val_bin, pr)\n",
    "auc_xgb = roc_auc_score(y_val_bin, px)\n",
    "auc_ens = roc_auc_score(y_val_bin, p_ens)\n",
    "\n",
    "# 5) Brier (baseline non calibr√©e)\n",
    "brier_uncal = brier_score_loss(y_val_bin, p_ens)\n",
    "\n",
    "print(\"=== DIAG ENSEMBLE (avant calibration) ===\")\n",
    "print(f\"Taux de d√©saccord RF vs XGB     : {disagree:.3f}\")\n",
    "print(f\"Corr√©lation des erreurs         : {err_corr:.3f}\")\n",
    "print(f\"ŒîF1 ensemble vs RF              : {d_rf:+.3f}\")\n",
    "print(f\"ŒîF1 ensemble vs XGB             : {d_xg:+.3f}\")\n",
    "print(f\"AUC RF / XGB / ENS              : {auc_rf:.3f} | {auc_xgb:.3f} | {auc_ens:.3f}\")\n",
    "print(f\"Brier (ensemble, uncal)         : {brier_uncal:.4f}\")\n",
    "\n",
    "# 6) McNemar (significativit√© des √©carts)\n",
    "try:\n",
    "    from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "    def mcnemar_p(yA, yB):\n",
    "        b01 = int(np.sum((yA==y_val_bin) & (yB!=y_val_bin)))  # A correct, B faux\n",
    "        b10 = int(np.sum((yA!=y_val_bin) & (yB==y_val_bin)))  # A faux, B correct\n",
    "        res = mcnemar([[0, b01],[b10, 0]], exact=True)\n",
    "        return res.pvalue, b01, b10\n",
    "\n",
    "    p_rf, b01_rf, b10_rf = mcnemar_p(yr, yens)\n",
    "    p_xg, b01_xg, b10_xg = mcnemar_p(yx, yens)\n",
    "\n",
    "    print(f\"McNemar RF vs Ensemble          : p={p_rf:.3f} (RF-corr/Ens-faux={b01_rf}, RF-faux/Ens-corr={b10_rf})\")\n",
    "    print(f\"McNemar XGB vs Ensemble         : p={p_xg:.3f} (XGB-corr/Ens-faux={b01_xg}, XGB-faux/Ens-corr={b10_xg})\")\n",
    "except Exception as e:\n",
    "    print(f\"McNemar indisponible ({e}). Installe 'statsmodels' si besoin.\")"
   ],
   "id": "1e4f5bf8a10555d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAG ENSEMBLE (avant calibration) ===\n",
      "Taux de d√©saccord RF vs XGB     : 0.364\n",
      "Corr√©lation des erreurs         : 0.083\n",
      "ŒîF1 ensemble vs RF              : +0.167\n",
      "ŒîF1 ensemble vs XGB             : +0.064\n",
      "AUC RF / XGB / ENS              : 0.900 | 0.800 | 0.867\n",
      "Brier (ensemble, uncal)         : 0.1618\n",
      "McNemar RF vs Ensemble          : p=1.000 (RF-corr/Ens-faux=1, RF-faux/Ens-corr=2)\n",
      "McNemar XGB vs Ensemble         : p=1.000 (XGB-corr/Ens-faux=0, XGB-faux/Ens-corr=1)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:51:31.979462Z",
     "start_time": "2025-10-28T14:51:31.856468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Calibration isotonic SANS 'cv=prefit' (compatible ‚â• 1.6)\n",
    "# =========================\n",
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "class IsoCalibrated:\n",
    "    \"\"\"\n",
    "    Wrappe un classifieur d√©j√† entra√Æn√© et applique une calibration isotonic\n",
    "    sur sa probabilit√© p(y=1|x).\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, iso_reg):\n",
    "        self.base_model = base_model\n",
    "        self.iso = iso_reg\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        p = self.base_model.predict_proba(X)[:, 1]\n",
    "        p_cal = self.iso.transform(p)\n",
    "        p_cal = np.clip(p_cal, 0.0, 1.0)\n",
    "        return np.vstack([1.0 - p_cal, p_cal]).T\n",
    "\n",
    "def fit_isotonic_on_val(prefit_model, X_val_pp, y_val_bin):\n",
    "    # proba brutes du mod√®le pr√©-entrain√©\n",
    "    p_val = prefit_model.predict_proba(X_val_pp)[:, 1]\n",
    "    # fit isotonic: monotone, clip hors bornes\n",
    "    iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso.fit(p_val, y_val_bin)\n",
    "    return IsoCalibrated(prefit_model, iso)\n",
    "\n",
    "# ---- Choix du mod√®le √† calibrer selon le champion ----\n",
    "calibrated = None\n",
    "ensemble_weights = None\n",
    "\n",
    "if champ_name == \"TS_RF\":\n",
    "    calibrated = fit_isotonic_on_val(rf_teacher, X_val_pp, y_val_bin)\n",
    "\n",
    "elif champ_name == \"TS_XGB\":\n",
    "    calibrated = fit_isotonic_on_val(xgb_teacher, X_val_pp, y_val_bin)\n",
    "\n",
    "elif champ_name == \"TS_Ensemble\":\n",
    "    # on calibre chaque composant s√©par√©ment puis on fait un blend pond√©r√© (sur proba d√©j√† calibr√©es)\n",
    "    rf_cal = fit_isotonic_on_val(rf_teacher,  X_val_pp, y_val_bin)\n",
    "    xg_cal = fit_isotonic_on_val(xgb_teacher, X_val_pp, y_val_bin)\n",
    "    w_rf, w_xg = candidates[\"TS_Ensemble\"][\"weights\"]\n",
    "    ensemble_weights = (w_rf, w_xg)\n",
    "\n",
    "    class CalEnsemble:\n",
    "        def __init__(self, rf, xg, w_rf, w_xg):\n",
    "            self.rf = rf; self.xg = xg; self.w_rf = float(w_rf); self.w_xg = float(w_xg)\n",
    "        def predict_proba(self, X):\n",
    "            pr = self.rf.predict_proba(X)[:, 1]   # d√©j√† calibr√©es (isotonic)\n",
    "            px = self.xg.predict_proba(X)[:, 1]\n",
    "            p  = self.w_rf*pr + self.w_xg*px\n",
    "            p  = np.clip(p, 0.0, 1.0)\n",
    "            return np.vstack([1.0 - p, p]).T\n",
    "\n",
    "    calibrated = CalEnsemble(rf_cal, xg_cal, w_rf, w_xg)\n",
    "\n",
    "assert calibrated is not None, \"Calibration introuvable.\""
   ],
   "id": "91f2eba17cb10aeb",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:56:22.963473Z",
     "start_time": "2025-10-28T14:56:22.829530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# ‚úÖ CONTR√îLE POST-CALIBRATION (sur VALIDATION)\n",
    "# ============================================\n",
    "\n",
    "# Proba non calibr√©es du champion (si champion ‚â† ensemble, adapte la cl√©)\n",
    "p_val_uncal = candidates[champ_name][\"proba\"] if champ_name in candidates else p_ens\n",
    "p_val_cal   = calibrated.predict_proba(X_val_pp)[:,1]\n",
    "\n",
    "# 1) Brier avant/apr√®s (doit baisser)\n",
    "brier_uncal = brier_score_loss(y_val_bin, p_val_uncal)\n",
    "brier_cal   = brier_score_loss(y_val_bin, p_val_cal)\n",
    "\n",
    "# 2) AUC avant/apr√®s (peut bouger un peu ; isotonic pr√©serve l‚Äôordre local)\n",
    "auc_uncal = roc_auc_score(y_val_bin, p_val_uncal)\n",
    "auc_cal   = roc_auc_score(y_val_bin, p_val_cal)\n",
    "\n",
    "print(\"=== POST-CALIBRATION (validation) ===\")\n",
    "print(f\"Brier uncal / cal                : {brier_uncal:.4f} ‚Üí {brier_cal:.4f}\")\n",
    "print(f\"AUC   uncal / cal                : {auc_uncal:.3f}  ‚Üí {auc_cal:.3f}\")"
   ],
   "id": "ea4b37d6b036e820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== POST-CALIBRATION (validation) ===\n",
      "Brier uncal / cal                : 0.1618 ‚Üí 0.0772\n",
      "AUC   uncal / cal                : 0.867  ‚Üí 0.950\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:51:38.356383Z",
     "start_time": "2025-10-28T14:51:38.055954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Seuil optimal sur validation\n",
    "# =========================\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "p_val = calibrated.predict_proba(X_val_pp)[:,1]\n",
    "ths = np.linspace(0.1, 0.9, 81)\n",
    "best_t, best_f1 = 0.5, -1\n",
    "for t in ths:\n",
    "    f1 = f1_score(y_val_bin, (p_val>=t).astype(int))\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "\n",
    "margin = 0.10  # zone grise\n",
    "p_good = float(np.clip(best_t, 0.3, 0.8))\n",
    "p_bad  = float(np.clip(best_t - margin, 0.1, p_good - 1e-3))\n",
    "\n",
    "print(f\"[Seuil (val)] t*={best_t:.3f} (F1={best_f1:.3f}) ‚Üí p_good={p_good:.3f} | p_bad={p_bad:.3f}\")"
   ],
   "id": "9a1dade60eb7a222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seuil (val)] t*=0.290 (F1=0.909) ‚Üí p_good=0.300 | p_bad=0.190\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:51:40.066618Z",
     "start_time": "2025-10-28T14:51:39.930343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# √âvaluation finale sur TEST\n",
    "# =========================\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "p_test = calibrated.predict_proba(X_test_pp)[:,1]\n",
    "y_test_pred = (p_test >= p_good).astype(int)\n",
    "\n",
    "print(\"\\n=== Test (final) ‚Äî Champion calibr√© ===\")\n",
    "print(classification_report(y_test_bin, y_test_pred, digits=3))\n",
    "print(\"Accuracy :\", accuracy_score(y_test_bin, y_test_pred))\n",
    "print(\"F1-score :\", f1_score(y_test_bin, y_test_pred))\n",
    "try:\n",
    "    print(\"ROC-AUC  :\", roc_auc_score(y_test_bin, p_test))\n",
    "except ValueError:\n",
    "    pass\n",
    "print(\"Confusion :\\n\", confusion_matrix(y_test_bin, y_test_pred))"
   ],
   "id": "1a147d05f853ba76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test (final) ‚Äî Champion calibr√© ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.625     0.769         8\n",
      "           1      0.500     1.000     0.667         3\n",
      "\n",
      "    accuracy                          0.727        11\n",
      "   macro avg      0.750     0.812     0.718        11\n",
      "weighted avg      0.864     0.727     0.741        11\n",
      "\n",
      "Accuracy : 0.7272727272727273\n",
      "F1-score : 0.6666666666666666\n",
      "ROC-AUC  : 0.75\n",
      "Confusion :\n",
      " [[5 3]\n",
      " [0 3]]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:57:33.126400Z",
     "start_time": "2025-10-28T14:57:32.373836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Inf√©rence sur TOUTES les soudures + export + bundle\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "# Recompose toutes les lignes (unlabeled PUIS labeled)\n",
    "X_all_raw_num = pd.concat([X_unlabeled[num_cols], X_labeled[num_cols]], axis=0)\n",
    "X_all_pp = pp(X_all_raw_num)  # m√™me imp/scale\n",
    "\n",
    "proba_all = calibrated.predict_proba(X_all_pp)[:,1]\n",
    "\n",
    "def decide(p):\n",
    "    if p >= p_good: return \"GOOD\"\n",
    "    if p <= p_bad:  return \"BAD\"\n",
    "    return \"UNCERTAIN\"\n",
    "\n",
    "df_final = pd.DataFrame({\n",
    "    \"GoodWeld_proba_SSL\": proba_all,\n",
    "    \"GoodWeld_label_SSL\": (proba_all >= p_good).astype(int)\n",
    "}, index=X_all_raw_num.index)\n",
    "df_final[\"Decision_SSL\"] = df_final[\"GoodWeld_proba_SSL\"].apply(decide)\n",
    "\n",
    "df_final_sorted = df_final.sort_values(\"GoodWeld_proba_SSL\", ascending=False).copy()\n",
    "df_final_sorted.insert(0, \"Rank\", np.arange(1, len(df_final_sorted)+1))\n",
    "df_final_sorted[\"GoodWeld_proba_pct\"] = (100*df_final_sorted[\"GoodWeld_proba_SSL\"]).round(2)\n",
    "\n",
    "# joindre meta utiles\n",
    "meta_cols = [c for c in [\"Weld ID\",\"Type of weld;_raw\",\"AC or DC_raw\",\"Electrode positive or negative_raw\",\n",
    "                         \"Current / A\",\"Voltage / V\",\"Heat input / kJmm-1\",\"Interpass temperature / ¬∞C\"] if c in df.columns]\n",
    "df_meta = df.loc[df_final_sorted.index, meta_cols] if meta_cols else pd.DataFrame(index=df_final_sorted.index)\n",
    "final_export = pd.concat([df_meta, df_final_sorted], axis=1)\n",
    "\n",
    "# exports\n",
    "OUT_DIR = Path.cwd() / \"outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "csv_path = OUT_DIR / f\"weld_predictions_ssl_{champ_name}_CAL_{timestamp}.csv\"\n",
    "final_export.to_csv(csv_path, index=True)\n",
    "print(f\"[‚úÖ] Export : {csv_path}\")\n",
    "print(\"\\nüìä R√©partition finale :\")\n",
    "print(final_export[\"Decision_SSL\"].value_counts())\n",
    "\n",
    "# bundle (sauvegarde prod)\n",
    "bundle = {\n",
    "    \"model_type\": champ_name,\n",
    "    \"model\": calibrated,\n",
    "    \"imputer\": imp,\n",
    "    \"scaler\": scaler,\n",
    "    \"num_cols\": num_cols,\n",
    "    \"p_good\": p_good,\n",
    "    \"p_bad\": p_bad,\n",
    "    \"meta_cols\": meta_cols\n",
    "}\n",
    "# si ensemble calibr√©, garde les poids\n",
    "if champ_name == \"TS_Ensemble\":\n",
    "    bundle[\"ensemble_weights\"] = ensemble_weights\n",
    "\n",
    "bundle_path = OUT_DIR / f\"ssl_champion_bundle_{champ_name}_{timestamp}.joblib\"\n",
    "joblib.dump(bundle, bundle_path)\n",
    "print(f\"[üíæ] Bundle sauvegard√© : {bundle_path}\")"
   ],
   "id": "a0fb10c41629da32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úÖ] Export : C:\\Users\\Guillaume PORET\\PycharmProjects\\pythonProject\\Central\\weld-quality\\V2 test semi supervides learning\\src\\processing\\outputs\\weld_predictions_ssl_TS_Ensemble_CAL_20251028_155732.csv\n",
      "\n",
      "üìä R√©partition finale :\n",
      "Decision_SSL\n",
      "BAD          1229\n",
      "GOOD          353\n",
      "UNCERTAIN      70\n",
      "Name: count, dtype: int64\n",
      "[üíæ] Bundle sauvegard√© : C:\\Users\\Guillaume PORET\\PycharmProjects\\pythonProject\\Central\\weld-quality\\V2 test semi supervides learning\\src\\processing\\outputs\\ssl_champion_bundle_TS_Ensemble_20251028_155732.joblib\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
